{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1) 필요 install 및 import, 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 필요 install 및 import, 환경설정\n",
    "!pip -q install \"transformers>=4.40.0\" \"accelerate>=0.26.0\" datasets sentencepiece evaluate sacrebleu torchmetrics rapidfuzz\n",
    "\n",
    "# NeuSpell은 환경에 따라 설치가 까다로울 수 있어 '가능하면' 설치 시도\n",
    "try:\n",
    "    !pip -q install neuspell\n",
    "    NEUSPELL_AVAILABLE = True\n",
    "except Exception:\n",
    "    NEUSPELL_AVAILABLE = False\n",
    "\n",
    "import os, random, warnings, difflib\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainerCallback\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "from torchmetrics.text import CharErrorRate\n",
    "from rapidfuzz.distance import Levenshtein as RLev\n",
    "\n",
    "# 환경 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"   # wandb 팝업 방지\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2) Google Drive mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) google drive mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "CSV_PATH = \"경로 입력\"  # 주어진 경로\n",
    "assert os.path.exists(CSV_PATH), f\"CSV not found at {CSV_PATH}\"\n",
    "print(\"OK:\", CSV_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3) NeuSpell 진행시 필요한 model(+tokenizer가 필요할 경우만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) NeuSpell 진행시 필요한 model (tokenizer 불필요)\n",
    "def build_neuspell_checker():\n",
    "    if not NEUSPELL_AVAILABLE:\n",
    "        return None\n",
    "    try:\n",
    "        # 가장 일반적인 예: Semi-Character LSTM\n",
    "        from neuspell import SclSTMChecker\n",
    "        checker = SclSTMChecker()\n",
    "        checker.from_pretrained()  # 기본 영어 체크포인트\n",
    "        return checker\n",
    "    except Exception:\n",
    "        try:\n",
    "            # 백업: BERT 기반\n",
    "            from neuspell import BertChecker\n",
    "            checker = BertChecker()\n",
    "            checker.from_pretrained(\"bert-base-cased\")\n",
    "            return checker\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "NEUSPELL = build_neuspell_checker()\n",
    "print(\"NeuSpell loaded:\", NEUSPELL is not None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4) NeuSpell 모델 진행 시 필요한 적용점 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) NeuSpell 적용점 (전처리 함수)\n",
    "def neuspell_preclean(texts: List[str]) -> List[str]:\n",
    "    \"\"\"NeuSpell로 철자/띄어쓰기 교정. 사용 불가면 원문 통과.\"\"\"\n",
    "    if NEUSPELL is None:\n",
    "        return texts\n",
    "    try:\n",
    "        return NEUSPELL.correct_strings(texts)\n",
    "    except Exception:\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5) ByT5 진행 시 필요한 model과 필요한 것 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) ByT5 로드\n",
    "MODEL_NAME = \"google/byt5-base\"   # 메모리 작으면 'google/byt5-small' 권장\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "print(\"ByT5 loaded:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6) ByT5 모델 진행 시 필요한 적용점 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) ByT5 적용점\n",
    "GEN_BEAMS = 1\n",
    "MAX_SOURCE_LEN = 96\n",
    "MAX_TARGET_LEN = 96\n",
    "\n",
    "# 학습에서 메모리 절약\n",
    "model.config.use_cache = False                  # 학습 시 decoder cache 비활성화\n",
    "# model.gradient_checkpointing_enable()         # 필요 시 메모리 추가 절약\n",
    "\n",
    "model.config.update({\n",
    "    \"num_beams\": GEN_BEAMS,\n",
    "    \"max_length\": MAX_TARGET_LEN\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7) 데이터 로드 및 전처리 과정 (9:1 split, NeuSpell 전처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 데이터 로드 및 전처리\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "assert {\"noise\",\"clean\"} <= set(df.columns), \"CSV must have columns: noise, clean\"\n",
    "df[\"noise\"] = df[\"noise\"].fillna(\"\").astype(str)\n",
    "df[\"clean\"] = df[\"clean\"].fillna(\"\").astype(str)\n",
    "\n",
    "# NeuSpell 전처리\n",
    "df[\"noise_preclean\"] = neuspell_preclean(df[\"noise\"].tolist())\n",
    "\n",
    "# 9:1 split\n",
    "train_df, val_df = train_test_split(df, test_size=0.05, random_state=SEED, shuffle=True)\n",
    "\n",
    "# HF Datasets 변환\n",
    "train_hf = HFDataset.from_pandas(train_df[[\"noise_preclean\",\"clean\"]], preserve_index=False)\n",
    "val_hf   = HFDataset.from_pandas(val_df[[\"noise_preclean\",\"clean\"]],   preserve_index=False)\n",
    "\n",
    "len(train_hf), len(val_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8) 전처리 함수 및 데이터 콜레이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) 전처리 함수 및 데이터 콜레이터\n",
    "def preprocess_fn(batch: Dict[str, List[str]]) -> Dict[str, List[int]]:\n",
    "    inputs  = batch[\"noise_preclean\"]\n",
    "    targets = batch[\"clean\"]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_SOURCE_LEN, truncation=True, padding=False)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=MAX_TARGET_LEN, truncation=True, padding=False)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_tok = train_hf.map(preprocess_fn, batched=True, remove_columns=train_hf.column_names)\n",
    "val_tok   = val_hf.map(preprocess_fn,   batched=True, remove_columns=val_hf.column_names)\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9) 평가 지표 로드 (필요 시 추가 메트릭 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "chrf = evaluate.load(\"chrf\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def _char_prf1_acc(pred_texts, label_texts):\n",
    "    # 문자 단위 얼라인으로 TP/FP/FN 집계 + 정확도\n",
    "    import difflib\n",
    "    TP = FP = FN = TN = 0\n",
    "    total_match = 0\n",
    "    total_char = 0\n",
    "\n",
    "    for p, g in zip(pred_texts, label_texts):\n",
    "        sm = difflib.SequenceMatcher(None, list(g), list(p))\n",
    "        for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "            if tag == \"equal\":\n",
    "                # 일치 문자는 TP로 처리 (교정과제의 맞춘 문자)\n",
    "                length = (i2 - i1)\n",
    "                TP += length\n",
    "                total_match += length\n",
    "                total_char += length\n",
    "            elif tag == \"replace\":\n",
    "                # 대체: g→p 길이를 기준으로 FP/FN 동시 발생으로 취급\n",
    "                FP += (j2 - j1)\n",
    "                FN += (i2 - i1)\n",
    "                total_char += max(i2 - i1, j2 - j1)\n",
    "            elif tag == \"delete\":\n",
    "                # 정답에만 있고 예측에는 없음 → FN\n",
    "                FN += (i2 - i1)\n",
    "                total_char += (i2 - i1)\n",
    "            elif tag == \"insert\":\n",
    "                # 예측에만 있음 → FP\n",
    "                FP += (j2 - j1)\n",
    "                total_char += (j2 - j1)\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall    = TP / (TP + FN + 1e-8)\n",
    "    f1        = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    char_acc  = total_match / max(1, total_char)\n",
    "    return precision, recall, f1, char_acc\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    import numpy as np\n",
    "    # 3D 로짓이면 argmax\n",
    "    if hasattr(preds, \"ndim\") and preds.ndim == 3:\n",
    "        pred_ids = preds.argmax(-1)\n",
    "    else:\n",
    "        pred_ids = preds\n",
    "\n",
    "    # -100 → pad id 복원\n",
    "    labels_np = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # [수정] 원래 labels 복원 대신 labels_np 사용\n",
    "    pred_texts = tokenizer.batch_decode(np.array(pred_ids), skip_special_tokens=True)\n",
    "    label_texts = tokenizer.batch_decode(labels_np, skip_special_tokens=True)\n",
    "    # 기존 메트릭\n",
    "    chrf_res = chrf.compute(predictions=pred_texts, references=label_texts, beta=1)\n",
    "    chrf_f1  = chrf_res[\"score\"] / 100.0\n",
    "    cer_sum  = sum(cer_metric.compute(predictions=[p], references=[g]) for p, g in zip(pred_texts, label_texts))\n",
    "    cer      = cer_sum / max(1, len(pred_texts))\n",
    "    exact    = sum(p == g for p, g in zip(pred_texts, label_texts)) / max(1, len(pred_texts))\n",
    "\n",
    "    # === 추가: 문자 단위 Precision/Recall/F1/Accuracy ===\n",
    "    prec, rec, f1, char_acc = _char_prf1_acc(pred_texts, label_texts)\n",
    "\n",
    "    return {\n",
    "        \"char_f1\": f1,          # 요청하신 F1\n",
    "        \"char_accuracy\": char_acc  # 요청하신 accuracy(문자 단위)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10) trainer 정의 (epoch 단위 로깅/평가/저장 + 콜백으로 예쁘게 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"transformers>=4.40.0\" \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers, inspect\n",
    "from transformers import Seq2SeqTrainingArguments, TrainingArguments\n",
    "\n",
    "# 10) trainer 정의 (변경분만)\n",
    "BATCH_SIZE  = 2\n",
    "NUM_EPOCHS  = 2\n",
    "LR          = 5e-6\n",
    "OUTPUT_DIR = \"출력 경로 입력\"\n",
    "\n",
    "# 수우정\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "  os.makedirs(OUTPUT_DIR)\n",
    "# 수정 끄읏\n",
    "\n",
    "PRED_LOG = []              # [{'epoch': 1, 'input': ..., 'preclean': ..., 'edit_src_word': ..., 'edit_new_word': ..., 'output': ...}, ...]\n",
    "MAX_VAL_SAVE = -1          # -1 이면 검증셋 전체 저장, 양이 많으면 200 등으로 제한\n",
    "# 구버전 호환: evaluation_strategy 대신 do_train/do_eval 사용\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # logging_strategy=\"steps\",\n",
    "    do_train=True,\n",
    "    do_eval=True,          # <-- 구버전에서 평가 활성화\n",
    "    logging_steps=500,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "\n",
    "    save_total_limit=2,\n",
    "\n",
    "    predict_with_generate=True,   # 평가시 생성\n",
    "    generation_max_length=MAX_TARGET_LEN,\n",
    "    generation_num_beams=4,\n",
    "    fp16=False,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# word-level 첫 변경 단어쌍 추정 (기존 그대로)\n",
    "def first_changed_word_pair(src: str, tgt: str) -> Tuple[str, str]:\n",
    "    import difflib\n",
    "    src_words = src.split()\n",
    "    tgt_words = tgt.split()\n",
    "    sm = difflib.SequenceMatcher(None, src_words, tgt_words)\n",
    "    for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "        if tag == \"replace\":\n",
    "            if i1 < len(src_words) and j1 < len(tgt_words):\n",
    "                return (src_words[i1], tgt_words[j1])\n",
    "        elif tag == \"delete\":\n",
    "            if i1 < len(src_words):\n",
    "                return (src_words[i1], \"\")\n",
    "        elif tag == \"insert\":\n",
    "            if j1 < len(tgt_words):\n",
    "                return (\"\", tgt_words[j1])\n",
    "    return (\"-\", \"-\")\n",
    "\n",
    "# ▼ 변경: 콘솔 출력 + DataFrame 로그 누적\n",
    "class EpochEndReporter(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # train/eval loss 요약\n",
    "        train_subset = train_tok.select(range(min(1024, len(train_tok))))\n",
    "        train_metrics = trainer.evaluate(eval_dataset=train_subset, metric_key_prefix=\"train\")\n",
    "        eval_metrics  = trainer.evaluate(metric_key_prefix=\"eval\")\n",
    "        print(f\"\\n[Epoch {int(state.epoch)}/{args.num_train_epochs}] \"\n",
    "              f\"train_loss={train_metrics.get('train_loss'):.4f} | \"\n",
    "              f\"eval_loss={eval_metrics.get('eval_loss'):.4f}\")\n",
    "\n",
    "        # ▼ DataFrame 저장용 로그 누적 (검증셋 전체 또는 샘플)\n",
    "        if MAX_VAL_SAVE == -1:\n",
    "            iter_df = val_df\n",
    "        else:\n",
    "            iter_df = val_df.sample(n=min(MAX_VAL_SAVE, len(val_df)), random_state=SEED)\n",
    "\n",
    "        for _, row in iter_df.iterrows():\n",
    "            src = str(row[\"noise\"])\n",
    "            pre = neuspell_preclean([src])[0]\n",
    "\n",
    "            # 생성 (predict_with_generate=False 이므로 수동 generate)\n",
    "            inputs = tokenizer(pre, return_tensors=\"pt\", truncation=True, max_length=MAX_SOURCE_LEN).to(model.device)\n",
    "            with torch.no_grad():\n",
    "                gen_ids = model.generate(**inputs, num_beams=GEN_BEAMS, max_length=MAX_TARGET_LEN)\n",
    "            out = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            ori_w, new_w = first_changed_word_pair(src, out)\n",
    "\n",
    "            PRED_LOG.append({\n",
    "                \"epoch\": int(state.epoch),\n",
    "                \"input\": src,\n",
    "                \"preclean\": pre,\n",
    "                \"edit_src_word\": ori_w,\n",
    "                \"edit_new_word\": new_w,\n",
    "                \"output\": out,\n",
    "            })\n",
    "\n",
    "STEP_LOG = []  # [{'step': int, 'loss': float}, {'step': int, 'eval_loss': float}, ...]\n",
    "\n",
    "class StepLogger(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if not logs:\n",
    "            return\n",
    "        row = {\"step\": state.global_step}\n",
    "        if \"loss\" in logs:\n",
    "            row[\"loss\"] = float(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "            row[\"eval_loss\"] = float(logs[\"eval_loss\"])\n",
    "        STEP_LOG.append(row)\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "      # CSV 저장\n",
    "      import pandas as pd, os\n",
    "      df = pd.DataFrame(STEP_LOG)\n",
    "      csv_path = os.path.join(OUTPUT_DIR, \"step_logs.csv\")\n",
    "      df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "      print(f\"[Saved] {csv_path}\")\n",
    "\n",
    "      # 그래프 저장\n",
    "      import matplotlib.pyplot as plt\n",
    "      plt.figure()\n",
    "\n",
    "        # [수정 시작] train_loss와 eval_loss를 그리는 방식을 분리합니다.\n",
    "\n",
    "      # 1. Train Loss: loss 값이 있는 모든 행 사용\n",
    "      if \"loss\" in df.columns:\n",
    "        train_df = df.dropna(subset=['loss'])\n",
    "        plt.plot(train_df[\"step\"], train_df[\"loss\"], label=\"train_loss\")\n",
    "\n",
    "      # 2. Eval Loss: eval_loss 값이 있는 행만 필터링하여 사용\n",
    "      if \"eval_loss\" in df.columns:\n",
    "        # NaN이 아닌 eval_loss 행만 필터링합니다.\n",
    "          eval_df = df.dropna(subset=['eval_loss'])\n",
    "          # 이제 eval_df[\"step\"]과 eval_df[\"eval_loss\"]의 길이는 동일합니다.\n",
    "          plt.plot(eval_df[\"step\"], eval_df[\"eval_loss\"], label=\"eval_loss\", marker='o')\n",
    "\n",
    "        # [수정 끝]\n",
    "\n",
    "      plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.legend(); plt.title(\"Step-wise Loss\")\n",
    "      png_path = os.path.join(OUTPUT_DIR, \"step_loss.png\")\n",
    "      plt.savefig(png_path, bbox_inches=\"tight\")\n",
    "      print(f\"[Saved] {png_path}\")\n",
    "\n",
    "# ==== 스텝 단위 수동 평가 콜백 (구버전 호환) ====\n",
    "EVAL_EVERY = 10  # 원하는 주기(스텝)로 조절\n",
    "\n",
    "class ManualStepEvaluator(TrainerCallback):\n",
    "    def __init__(self, eval_every=EVAL_EVERY):\n",
    "        self.eval_every = eval_every\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        # global_step이 eval 주기일 때 수동 평가\n",
    "        if state.global_step > 0 and state.global_step % self.eval_every == 0:\n",
    "            # 구버전 호환: 전역 trainer 참조로 직접 평가 실행\n",
    "            metrics = trainer.evaluate(metric_key_prefix=\"stepeval\")\n",
    "            # 스텝 정보와 함께 수동 로그\n",
    "            metrics = {f\"stepeval_{k}\": v for k, v in metrics.items()}\n",
    "            metrics[\"stepeval_step\"] = state.global_step\n",
    "            trainer.log(metrics)\n",
    "\n",
    "# 등록\n",
    "#trainer.add_callback(ManualStepEvaluator(EVAL_EVERY))\n",
    "trainer.add_callback(EpochEndReporter())\n",
    "trainer.add_callback(StepLogger())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#11) 모델 학습 및 검증 (epoch=3, epoch마다 train/eval loss 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) 모델 학습 및 검증 + CSV 저장\n",
    "train_result = trainer.train()\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, \"stage1_silver\"))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"stage1_silver\"))\n",
    "\n",
    "print(\"\\n[Training Finished]\")\n",
    "print(train_result)\n",
    "\n",
    "# === (NEW) Save .pt (state_dict) ===\n",
    "import os, torch\n",
    "\n",
    "pt_dir = os.path.join(OUTPUT_DIR, \"stage1_silver\")\n",
    "os.makedirs(pt_dir, exist_ok=True)\n",
    "\n",
    "# 메모리·호환성을 위해 CPU 텐서로 변환해 저장\n",
    "state_dict_cpu = {k: v.to(\"cpu\") for k, v in model.state_dict().items()}\n",
    "pt_path = os.path.join(pt_dir, \"NeuSpell_ByT5_Weight.pt\")\n",
    "torch.save(state_dict_cpu, pt_path)\n",
    "\n",
    "print(f\"[Saved .pt] {pt_path}\")\n",
    "\n",
    "\n",
    "# ▼ 추가: 에폭별 검증 예측 로그를 CSV로 저장\n",
    "import pandas as pd\n",
    "pred_df = pd.DataFrame(PRED_LOG, columns=[\"epoch\",\"input\",\"preclean\",\"edit_src_word\",\"edit_new_word\",\"output\"])\n",
    "save_path = os.path.join(OUTPUT_DIR, \"val_predictions_by_epoch2.csv\")\n",
    "pred_df.to_csv(save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"[Saved] {save_path}  (rows={len(pred_df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) 추론 함수 정의 및 Gradio 실행 (조건 3, 4)\n",
    "import torch, os\n",
    "# Gradio 사용을 위한 설치 및 임포트\n",
    "!pip -q install gradio\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# 이전 셀에서 정의된 변수들을 재참조\n",
    "MODEL_NAME = \"google/byt5-base\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_SOURCE_LEN = 96\n",
    "MAX_TARGET_LEN = 96\n",
    "GEN_BEAMS = 4\n",
    "OUTPUT_DIR = \"위와 동일한 경로\" # 조건 1의 경로\n",
    "\n",
    "# 1. 학습된 모델 및 토크나이저 로드 (11번 셀에서 저장된 경로 사용)\n",
    "CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, \"stage1_silver\")\n",
    "PT_PATH = os.path.join(CHECKPOINT_DIR, \"NeuSpell_ByT5_Weight.pt\")\n",
    "\n",
    "try:\n",
    "    # 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_DIR)\n",
    "    # 기본 모델 구조 로드\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "    # .pt 파일(state_dict) 로드 및 적용\n",
    "    state_dict = torch.load(PT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE).eval()\n",
    "    print(f\"[Model Loaded] Model state loaded from {PT_PATH} and moved to {DEVICE}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] 모델 로드 실패: {e}\")\n",
    "    # 모델 로드 실패 시에는 Gradio 실행에 문제가 생길 수 있습니다.\n",
    "\n",
    "\n",
    "# [조건 3] Inference 함수 정의\n",
    "def predict_correction(text_input: str) -> str:\n",
    "    \"\"\"\n",
    "    주어진 문장에 대해 철자 교정 예측 결과를 반환합니다.\n",
    "    \"\"\"\n",
    "    if not text_input:\n",
    "        return \"입력 문장이 비어 있습니다.\"\n",
    "\n",
    "    # 1. NeuSpell 전처리 (4번 셀의 함수 neuspell_preclean 사용)\n",
    "    # 이 셀은 새로운 환경(커널)에서도 실행될 수 있으므로,\n",
    "    # NEUSPELL 변수 및 neuspell_preclean 함수가 정의되어 있다는 가정이 필요합니다.\n",
    "    try:\n",
    "        precleaned_text = neuspell_preclean([text_input])[0]\n",
    "    except NameError:\n",
    "        precleaned_text = text_input # NeuSpell이 정의되지 않은 경우 원문 사용\n",
    "\n",
    "    # 2. 토크나이징 및 모델 입력\n",
    "    inputs = tokenizer(\n",
    "        precleaned_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_SOURCE_LEN\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # 3. 모델 생성 (Inference)\n",
    "    with torch.no_grad():\n",
    "        gen_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_beams=GEN_BEAMS,\n",
    "            max_length=MAX_TARGET_LEN\n",
    "        )\n",
    "\n",
    "    # 4. 결과 디코딩\n",
    "    output_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# [조건 4] Gradio UI 통합 및 실행\n",
    "try:\n",
    "    iface = gr.Interface(\n",
    "        fn=predict_correction, # 위에 정의한 추론 함수\n",
    "        inputs=gr.Textbox(\n",
    "            label=\"오류가 있는 문장 입력 (Noise Input)\",\n",
    "            placeholder=\"예: This is a exammple senntence.\"\n",
    "        ),\n",
    "        outputs=gr.Textbox(\n",
    "            label=\"교정된 결과 (Corrected Output)\"\n",
    "        ),\n",
    "        title=\"NeuT5 기반 철자 교정 모델 (ByT5)\",\n",
    "        description=\"학습된 NeuT5 모델을 사용하여 입력 문장의 철자 및 문법을 교정합니다.\",\n",
    "    )\n",
    "\n",
    "    # Gradio 실행 (Colab 환경에서 public_share=True 권장)\n",
    "    iface.launch(share=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Gradio 인터페이스 실행에 실패했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#빠른 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Quick Demo =========\n",
    "if __name__ == \"__main__\":\n",
    "    demo_inputs = [\n",
    "        \"He go to school every day.\",\n",
    "        \"She has two child.\",\n",
    "        \"She is teacher.\",\n",
    "        \"He arrived to the airport on time.\",\n",
    "        \"I every day go to school.\",\n",
    "        \"He told that he was tired.\",\n",
    "        \"This is very importent information.\",\n",
    "    ]\n",
    "    tok_inf, mdl_inf = load_trained_model_for_inference()\n",
    "    results = correct_sentences(demo_inputs, tok_inf, mdl_inf)\n",
    "    for r in results:\n",
    "        print(f\"IN : {r['input']}\")\n",
    "        print(f\"PRE: {r['preclean']}\")\n",
    "        print(f\"OUT: {r['output']}\")\n",
    "        print(\"-\"*40)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
