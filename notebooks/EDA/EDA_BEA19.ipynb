{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dldmstj0531/GEC/blob/main/notebooks/EDA/EDA_BEA19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfXmFyyG89aE"
      },
      "source": [
        "# **BEA2019(W&I+LOCNESS)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7x2vL26QwYQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q koreanize-matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XuduX2y9Agu"
      },
      "outputs": [],
      "source": [
        "!pip install python-Levenshtein seaborn nltk sacremoses pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhivr_Kq9BET"
      },
      "outputs": [],
      "source": [
        "import warnings, os, json, ast, math, pathlib, shutil\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import Levenshtein  # 문자열 편집 거리 계산\n",
        "from collections import Counter\n",
        "import difflib  # Diff 분석\n",
        "from tqdm.auto import tqdm  # 진행률 표시\n",
        "\n",
        "# 시각화 라이브러리\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MqorJ0b9Dll"
      },
      "outputs": [],
      "source": [
        "# pandas 출력 옵션 및 경고 설정\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# tqdm의 pandas integration 활성화\n",
        "tqdm.pandas()\n",
        "\n",
        "# 마이너스 기호 깨짐 방지\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "# NLTK 토크나이저 다운로드 (최초 1회 필요)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# 시각화 스타일 설정\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False # 마이너스 기호 깨짐 방지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAcEPxYc9En4"
      },
      "outputs": [],
      "source": [
        "# Colab 전용: tqdm, pandas, matplotlib 설치/업데이트\n",
        "!pip -q install pandas tqdm matplotlib\n",
        "\n",
        "# 구글 드라이브 마운트: EDA 결과물만 저장하고, 대형 TSV는 /content 에 임시 저장 권장\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gETKucu9WqM"
      },
      "source": [
        "## 1. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AXMxleJ9GDT"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Projects/LikeLion/실전프로젝트02\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsVlIEUp9he2"
      },
      "outputs": [],
      "source": [
        "!tar -xvzf /content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness_v2.1.bea19.tar.gz\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLgdm9Xr9jgn"
      },
      "outputs": [],
      "source": [
        "%cd ./wi+locness/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFG1-i4X9mpf"
      },
      "outputs": [],
      "source": [
        "!head json/A.train.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajyzl52k9nm6"
      },
      "outputs": [],
      "source": [
        "!head m2/A.train.gold.bea19.m2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdoYZU5AC8PE"
      },
      "source": [
        "### JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBCne9HM9oY0"
      },
      "outputs": [],
      "source": [
        "# JSON\n",
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/json/A.train.json\",\n",
        "    \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/json/B.train.json\",\n",
        "    \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/json/C.train.json\",\n",
        "]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"경고: 파일을 찾을 수 없습니다 - {file_path}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line_num, line in enumerate(f, 1):\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    all_data.append(data)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"경고: JSON 파싱 오류 건너<0xEB><0>뜁니다 (파일: {file_path}, 라인: {line_num}): {e}\")\n",
        "                    continue\n",
        "    except Exception as e:\n",
        "        print(f\"파일 읽기 중 오류 발생 {file_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "# all_data 확인\n",
        "df_json = pd.DataFrame(all_data)\n",
        "print(df_json.shape)\n",
        "df_json.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKFkBvUzCguf"
      },
      "outputs": [],
      "source": [
        "# JSON 저장 경로\n",
        "save_path = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/bea19_json.csv\"\n",
        "\n",
        "# JSON csv 저장\n",
        "df_json.to_csv(save_path, index=False)\n",
        "\n",
        "# JSON 확인\n",
        "if os.path.exists(save_path):\n",
        "    print(f\"파일 저장 확인: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fvakMfBC-Sy"
      },
      "source": [
        "### M2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83bmuVx7C3mf"
      },
      "outputs": [],
      "source": [
        "# M2\n",
        "def parse_m2_file(path):\n",
        "    rows = []\n",
        "    sent_id = -1\n",
        "    cur_sentence = None\n",
        "\n",
        "    # m2는 문장 블록이 빈 줄로 구분됨\n",
        "    def flush_sentence():\n",
        "        # 필요시 문장 단위 후처리용 훅\n",
        "        pass\n",
        "\n",
        "    # 인코딩 문제 시 utf-8 → latin-1 폴백\n",
        "    try_encodings = [\"utf-8\", \"utf-8-sig\", \"latin-1\"]\n",
        "    for enc in try_encodings:\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=enc) as f:\n",
        "                lines = f.readlines()\n",
        "            break\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "    else:\n",
        "        raise UnicodeDecodeError(\"읽기 실패\", b\"\", 0, 1, \"모든 후보 인코딩 실패\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.rstrip(\"\\n\")\n",
        "        if not line:\n",
        "            flush_sentence()\n",
        "            continue\n",
        "\n",
        "        if line.startswith(\"S \"):\n",
        "            sent_id += 1\n",
        "            cur_sentence = line[2:].strip()\n",
        "        elif line.startswith(\"A \"):\n",
        "            if cur_sentence is None:\n",
        "                # S 없이 A가 먼저 오는 비정상 라인 방어\n",
        "                continue\n",
        "            # \"A 5 6|||R:OTHER|||- sized|||REQUIRED|||-NONE-|||0\"\n",
        "            try:\n",
        "                # 앞의 위치정보 \"A 5 6\" 추출\n",
        "                head, rest = line[2:].split(\"|||\", 1)  # \"5 6\", \"R:OTHER|||...|||0\"\n",
        "                head = head.strip()\n",
        "                start_str, end_str = head.split()\n",
        "                a_start, a_end = int(start_str), int(end_str)\n",
        "\n",
        "                parts = rest.split(\"|||\")\n",
        "                # parts = [err_type, correction, status, comment, annotator, ...]\n",
        "                # 일부 코퍼스는 길이가 5 미만/초과일 수 있어 안전 처리\n",
        "                err_type   = parts[0].strip() if len(parts) > 0 else \"\"\n",
        "                correction = parts[1].strip() if len(parts) > 1 else \"\"\n",
        "                status     = parts[2].strip() if len(parts) > 2 else \"\"\n",
        "                comment    = parts[3].strip() if len(parts) > 3 else \"\"\n",
        "                annotator  = parts[4].strip() if len(parts) > 4 else \"\"\n",
        "\n",
        "                rows.append({\n",
        "                    \"sent_id\": sent_id,\n",
        "                    \"source\": cur_sentence,     # 원문 문장\n",
        "                    \"a_start\": a_start,         # 토큰 시작 인덱스 (포함)\n",
        "                    \"a_end\": a_end,             # 토큰 끝 인덱스 (배타/포함은 코퍼스 정의에 따름; 보통 끝은 배타)\n",
        "                    \"err_type\": err_type,       # 예: R:OTHER, M:PREP, U:PREP 등\n",
        "                    \"correction\": correction,   # 수정안(빈 문자열일 수 있음)\n",
        "                    \"status\": status,           # 예: REQUIRED / OPTIONAL 등\n",
        "                    \"comment\": comment,         # 코멘트(없으면 -NONE-)\n",
        "                    \"annotator\": annotator      # 주석자 ID (숫자 문자열)\n",
        "                })\n",
        "            except Exception as e:\n",
        "                # 파싱 실패 라인은 그냥 건너뜀\n",
        "                # print(f\"[WARN] parse fail in {path}: {e}\\n  line: {line}\")\n",
        "                continue\n",
        "        else:\n",
        "            # 다른 접두어는 무시(예: 'T ' 등이 있는 변형 코퍼스)\n",
        "            continue\n",
        "\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RlWsB6j_eBg"
      },
      "outputs": [],
      "source": [
        "# 여러 m2 to DataFrame 만들기\n",
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/m2/A.train.gold.bea19.m2\",\n",
        "    \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/m2/B.train.gold.bea19.m2\",\n",
        "    \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/m2/C.train.gold.bea19.m2\",\n",
        "]\n",
        "\n",
        "all_rows = []\n",
        "for fp in file_paths:\n",
        "    if not os.path.exists(fp):\n",
        "        print(f\"경고: 파일을 찾을 수 없습니다 - {fp}\")\n",
        "        continue\n",
        "    rows = parse_m2_file(fp)\n",
        "    # 원하면 파일 구분용 컬럼 추가\n",
        "    for r in rows:\n",
        "        r[\"m2_file\"] = os.path.basename(fp)\n",
        "    all_rows.extend(rows)\n",
        "\n",
        "df_m2 = pd.DataFrame(all_rows, columns=[\n",
        "    \"m2_file\", \"sent_id\", \"source\", \"a_start\", \"a_end\",\n",
        "    \"err_type\", \"correction\", \"status\", \"comment\", \"annotator\"\n",
        "])\n",
        "\n",
        "print(df_m2.shape)\n",
        "df_m2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKBQX1DcAkeP"
      },
      "outputs": [],
      "source": [
        "# M2 저장 경로\n",
        "save_path = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/bea19_m2.csv\"\n",
        "\n",
        "# M2 csv 저장\n",
        "df_m2.to_csv(save_path, index=False)\n",
        "\n",
        "# M2 확인\n",
        "if os.path.exists(save_path):\n",
        "    print(f\"파일 저장 확인: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25O2fQrKdRrS"
      },
      "source": [
        "### src/tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KKW507rdUso"
      },
      "outputs": [],
      "source": [
        "src_path = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/src_tgt/ABC.train.src\"\n",
        "tgt_path = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/src_tgt/ABC.train.tgt\"\n",
        "\n",
        "\n",
        "# 줄 단위로 읽기 (빈 줄도 포함해서)\n",
        "with open(src_path, encoding=\"utf-8\") as f:\n",
        "    src_lines = [l.rstrip(\"\\n\") for l in f]\n",
        "\n",
        "with open(tgt_path, encoding=\"utf-8\") as f:\n",
        "    tgt_lines = [l.rstrip(\"\\n\") for l in f]\n",
        "\n",
        "print(f\"src: {len(src_lines)} lines\")\n",
        "print(f\"tgt: {len(tgt_lines)} lines\")\n",
        "\n",
        "# 2) 빈 줄 인덱스 찾기\n",
        "src_empty_idx = [i for i, line in enumerate(src_lines) if line.strip() == \"\"]\n",
        "tgt_empty_idx = [i for i, line in enumerate(tgt_lines) if line.strip() == \"\"]\n",
        "\n",
        "print(f\"src 빈 줄 개수: {len(src_empty_idx)}\")\n",
        "print(f\"tgt 빈 줄 개수: {len(tgt_empty_idx)}\")\n",
        "\n",
        "# 3) tgt가 빈 줄인 곳의 src/tgt 내용 같이 보기\n",
        "print(\"\\n=== tgt가 빈 줄인 위치들 ===\")\n",
        "for i in tgt_empty_idx:\n",
        "    src_val = src_lines[i]\n",
        "    tgt_val = tgt_lines[i]\n",
        "    print(f\"[{i}]\")\n",
        "    print(f\"  src: {repr(src_val)}\")\n",
        "    print(f\"  tgt: {repr(tgt_val)}\")\n",
        "\n",
        "# # 빈 tgt를 src로 대체\n",
        "# fixed_tgt_lines = [t if t.strip() != \"\" else s for s, t in zip(src_lines, tgt_lines)]\n",
        "\n",
        "# # 검증\n",
        "# empties_after = sum(1 for t in fixed_tgt_lines if t.strip() == \"\")\n",
        "# print(\"empties_after:\", empties_after)  # 0 이어야 정상\n",
        "# assert len(src_lines) s== len(fixed_tgt_lines)\n",
        "\n",
        "# # 빈 줄이 있는 위치 찾기\n",
        "# src_empty_idx = [i for i, line in enumerate(src_lines) if line.strip() == \"\"]\n",
        "# tgt_empty_idx = [i for i, line in enumerate(tgt_lines) if line.strip() == \"\"]\n",
        "\n",
        "df = pd.DataFrame({\"noise\": src_lines, \"clean\": tgt_lines})\n",
        "print(df.shape)\n",
        "print(df.isnull().sum())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI_Iv4AGdUqO"
      },
      "outputs": [],
      "source": [
        "# SRC/TGT 저장 경로\n",
        "save_path = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/bea19_train.csv\"\n",
        "\n",
        "# SRC/TGT csv 저장\n",
        "df.to_csv(save_path, index=False)\n",
        "\n",
        "# SRC/TGT 확인\n",
        "if os.path.exists(save_path):\n",
        "    print(f\"파일 저장 확인: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrdWBf4VECIh"
      },
      "source": [
        "## 2. EDA(json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbTB90sRTV-s"
      },
      "source": [
        "### 기본 통계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtMbh1CGD3y-"
      },
      "outputs": [],
      "source": [
        "df_json = pd.read_csv(\"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/bea19_json.csv\")\n",
        "df_json.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrKJf7FBSdhm"
      },
      "outputs": [],
      "source": [
        "print(df_json.shape)\n",
        "print(df_json[\"id\"].value_counts().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbrtuCgYTZr5"
      },
      "source": [
        "### `text` 단어 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5uxuFnYTYQi"
      },
      "outputs": [],
      "source": [
        "df_json[\"text_word_len\"] = df_json[\"text\"].astype(str).str.split().str.len()\n",
        "display(df_json.head())\n",
        "\n",
        "# 문장 길이 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_json[\"text_word_len\"], kde=True, bins=50)\n",
        "plt.title(\"BEA-19 (JSON): 문장 길이(단어 수) 분포\")\n",
        "plt.xlabel(\"단어 수\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.xlim(0, 200)\n",
        "plt.show()\n",
        "\n",
        "# 평균 및 최대 문장 길이 출력\n",
        "print(f\"평균 문장 길이: {df_json['text_word_len'].mean():.2f}\")\n",
        "print(f\"최대 문장 길이: {df_json['text_word_len'].max()}\")\n",
        "print(f\"문장 길이 상위 95% 지점: {df_json['text_word_len'].quantile(0.95):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUxqdNGVTf_f"
      },
      "source": [
        "### `edits` 개수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvwCyy_-TdDy"
      },
      "outputs": [],
      "source": [
        "print(df_json[\"text\"].iloc[0])\n",
        "df_json[\"edits\"].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlx7qboGThHg"
      },
      "outputs": [],
      "source": [
        "# 각 문장당 edit(수정) 개수 계산\n",
        "def count_edits_fixed(ed):\n",
        "    # NaN/None\n",
        "    if ed is None or (isinstance(ed, float) and math.isnan(ed)):\n",
        "        return 0\n",
        "\n",
        "    # 문자열(JSON 또는 파이썬 리터럴) -> 파싱\n",
        "    if isinstance(ed, str):\n",
        "        s = ed.strip()\n",
        "        try:\n",
        "            ed = json.loads(s)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ed = ast.literal_eval(s)\n",
        "            except Exception:\n",
        "                return 0\n",
        "\n",
        "    # 이미 [[score, [[s,e,repl], ...]]]\n",
        "    if (isinstance(ed, (list, tuple)) and ed\n",
        "        and isinstance(ed[0], (list, tuple)) and len(ed[0]) > 1\n",
        "        and isinstance(ed[0][1], (list, tuple))):\n",
        "        inner = ed[0][1]\n",
        "        return sum(1 for x in inner if isinstance(x, (list, tuple)) and len(x) == 3)\n",
        "\n",
        "    # 이미 [[s,e,repl], ...] 형태\n",
        "    if (isinstance(ed, (list, tuple)) and ed\n",
        "        and all(isinstance(x, (list, tuple)) and len(x) == 3 for x in ed)):\n",
        "        return len(ed)\n",
        "\n",
        "    return 0\n",
        "\n",
        "df_json[\"num_edits\"] = df_json[\"edits\"].apply(count_edits_fixed)\n",
        "df_json.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkadsIyPTmGg"
      },
      "outputs": [],
      "source": [
        "# 문장당 Edit 개수 분포 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "edit_counts_vis = df_json[\"num_edits\"].value_counts().sort_index()\n",
        "edit_counts_vis = edit_counts_vis[edit_counts_vis.index <= 20]\n",
        "sns.barplot(x=edit_counts_vis.index, y=edit_counts_vis.values)\n",
        "plt.title(\"BEA-19 (JSON): 문장당 Edit 개수 분포 (상위 20개)\")\n",
        "plt.xlabel(\"문장당 Edit 개수\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 평균 Edit 개수 및 Edit가 있는 문장 비율 출력\n",
        "print(f\"평균 Edit 개수: {df_json['num_edits'].mean():.2f}\")\n",
        "print(f\"Edit가 하나 이상 있는 문장 비율: {(df_json['num_edits'] > 0).mean()*100:.2f}%\")\n",
        "print(f\"Edit가 없는 문장 (No-Op) 비율: {(df_json['num_edits'] == 0).mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7qka45RTsCJ"
      },
      "source": [
        "[해석]\n",
        "\n",
        "- 많은 오류를 포함\n",
        "- 하나의 문장 내에서 많은 오류를 동시에 탐지하고 수정해야 함\n",
        "    - `Seq2Seq(T5, BART)` 모델 적합성\n",
        "- 수정없는 데이터 비율이 낮기 때문에 모델이 올바른 문장까지 불필요하게 수정하려는 경향이 보일 수도 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX2IPI1UT-rY"
      },
      "source": [
        "## 2. EDA(SRC/TGT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWveS-zVTqDp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/bea19_train.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 오류 존재 및 빈도 분석"
      ],
      "metadata": {
        "id": "mT5S5Mf_D9VM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAvuCHL7hPmW"
      },
      "outputs": [],
      "source": [
        "# 'noisy'와 'clean'이 다른 경우 True\n",
        "df[\"is_corrected\"] = (df[\"noise\"] != df[\"clean\"])\n",
        "\n",
        "correction_ratio = df[\"is_corrected\"].mean()\n",
        "\n",
        "print(f\"전체 샘플 중 수정된 샘플의 비율: {correction_ratio:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 오류 수정 규모 (편집 거리) 분석"
      ],
      "metadata": {
        "id": "-x-2ZxesINMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# 2-1. 문자(Character) 레벨 편집 거리\n",
        "# ---------------------------------\n",
        "df[\"char_edit_distance\"] = df.apply(\n",
        "    lambda row: Levenshtein.distance(str(row[\"noise\"]), str(row[\"clean\"])),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"\\n[문자 레벨 편집 거리 통계]\")\n",
        "# 오류가 있는 샘플들만 통계 확인\n",
        "print(df[df[\"is_corrected\"]][\"char_edit_distance\"].describe())"
      ],
      "metadata": {
        "id": "_gCHlcYYHst1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# 2-2. 토큰(Word) 레벨 편집 거리\n",
        "# ---------------------------------\n",
        "\n",
        "def get_token_edit_distance(row):\n",
        "    noise_tokens = nltk.word_tokenize(str(row[\"noise\"]))\n",
        "    clean_tokens = nltk.word_tokenize(str(row[\"clean\"]))\n",
        "    return nltk.edit_distance(noise_tokens, clean_tokens)\n",
        "\n",
        "# tqdm을 사용하여 apply 진행 상황 확인\n",
        "tqdm.pandas(desc=\"Token Edit Distance 계산 중\")\n",
        "df[\"token_edit_distance\"] = df.progress_apply(get_token_edit_distance, axis=1)\n",
        "\n",
        "print(\"\\n[토큰 레벨 편집 거리 통계]\")\n",
        "# 오류가 있는 샘플들만 통계 확인\n",
        "print(df[df[\"is_corrected\"]][\"token_edit_distance\"].describe())"
      ],
      "metadata": {
        "id": "31IBg8yUIc8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# 2-3. 시각화\n",
        "# ---------------------------------\n",
        "print(\"\\n[편집 거리 분포 시각화 (수정된 샘플 대상)]\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 문자 편집 거리 (100 이상은 하나로 묶음)\n",
        "sns.histplot(df[df[\"is_corrected\"]][\"char_edit_distance\"].clip(upper=100), bins=50, ax=axes[0])\n",
        "axes[0].set_title(\"Character Edit Distance Distribution (Corrected Samples)\")\n",
        "axes[0].set_xlabel(\"Char Edit Distance (Clipped at 100)\")\n",
        "\n",
        "# 토큰 편집 거리 (20 이상은 하나로 묶음)\n",
        "sns.histplot(df[df[\"is_corrected\"]][\"token_edit_distance\"].clip(upper=20), bins=20, ax=axes[1])\n",
        "axes[1].set_title(\"Token Edit Distance Distribution (Corrected Samples)\")\n",
        "axes[1].set_xlabel(\"Token Edit Distance (Clipped at 20)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AP_2GEo1Izyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 히스토그램이 1~3과 같이 낮은 값에 몰려있다면, 대부분 간단한 수정(오타, 관사)\n",
        "- 꼬리가 길거나 분포가 넓다면(e.g., 10 이상), 문장 구조를 바꾸는 복잡한 수정이 많다?"
      ],
      "metadata": {
        "id": "PpnlE1FlQPly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 오류 유형 분석 (Token Diff)"
      ],
      "metadata": {
        "id": "Z8_ppj5aI6i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter 객체 초기화\n",
        "deleted_words = Counter()\n",
        "added_words = Counter()\n",
        "replaced_pairs = Counter()\n",
        "\n",
        "# 수정된 샘플들만 순회\n",
        "corrected_df = df[df[\"is_corrected\"]]\n",
        "\n",
        "for _, row in tqdm(corrected_df.iterrows(), total=corrected_df.shape[0], desc=\"Diff 패턴 분석 중\"):\n",
        "    noisy_tokens = nltk.word_tokenize(str(row[\"noise\"]))\n",
        "    clean_tokens = nltk.word_tokenize(str(row[\"clean\"]))\n",
        "\n",
        "    # difflib.SequenceMatcher를 사용하여 차이점 분석\n",
        "    matcher = difflib.SequenceMatcher(None, noisy_tokens, clean_tokens)\n",
        "\n",
        "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "        if tag == \"delete\":\n",
        "            # 삭제된 토큰들 추가\n",
        "            deleted_words.update(noisy_tokens[i1:i2])\n",
        "\n",
        "        elif tag == \"insert\":\n",
        "            # 추가된 토큰들 추가\n",
        "            added_words.update(clean_tokens[j1:j2])\n",
        "\n",
        "        elif tag == \"replace\":\n",
        "            # 대체된 토큰 쌍 추가\n",
        "            # (noisy_tokens[i1:i2], clean_tokens[j1:j2] 형태)\n",
        "            # 여기서는 간단히 1:1 매칭만 가정 (실제로는 N:M일 수 있음)\n",
        "            noisy_segment = \" \".join(noisy_tokens[i1:i2])\n",
        "            clean_segment = \" \".join(clean_tokens[j1:j2])\n",
        "            replaced_pairs.update([(noisy_segment, clean_segment)])\n",
        "\n",
        "print(\"\\n[가장 많이 삭제된 단어 Top 20]\")\n",
        "print(deleted_words.most_common(20))\n",
        "\n",
        "print(\"\\n[가장 많이 추가된 단어 Top 20]\")\n",
        "print(added_words.most_common(20))\n",
        "\n",
        "print(\"\\n[가장 많이 대체된 (Noisy -> Clean) 쌍 Top 20]\")\n",
        "print(replaced_pairs.most_common(20))"
      ],
      "metadata": {
        "id": "7jm9_-zYI7gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장 길이와 오류 상관관계"
      ],
      "metadata": {
        "id": "8NgDhXvqJHNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'noisy' 문장의 토큰 길이 계산\n",
        "df[\"noisy_token_count\"] = df[\"noise\"].apply(lambda x: len(nltk.word_tokenize(str(x))))\n",
        "\n",
        "# 문장 길이와 토큰 편집 거리 간의 상관관계 계산\n",
        "correlation = df[\"noisy_token_count\"].corr(df[\"token_edit_distance\"])\n",
        "\n",
        "print(f\"문장 길이(토큰 수)와 토큰 편집 거리 간의 상관계수: {correlation:.4f}\")\n",
        "\n",
        "if correlation > 0.3:\n",
        "    print(\"- 문장이 길수록 수정량이 많아지는 경향이 있다.\")\n",
        "    print(\"- 모델이 긴 문맥(long-range dependency)을 잘 처리하는지 확인이 필요.\")\n",
        "elif correlation < 0.1:\n",
        "    print(\"- 문장 길이와 오류 발생은 큰 직접적 관계가 없을 수 있다.\")\n",
        "\n",
        "\n",
        "# 시각화 (샘플 수가 많으므로 2D 히스토그램 또는 jointplot(sample)이 유용)\n",
        "print(\"\\n[문장 길이 vs 토큰 편집 거리 시각화 (샘플링)]\")\n",
        "# 데이터가 너무 많으면 오래 걸리므로 5000개 샘플링\n",
        "sample_df = df.sample(n=min(5000, len(df)))\n",
        "\n",
        "sns.jointplot(\n",
        "    data=sample_df,\n",
        "    x=\"noisy_token_count\",\n",
        "    y=\"token_edit_distance\",\n",
        "    kind=\"hist\", # 'scatter', 'kde', 'hex' 등으로 변경 가능\n",
        "    xlim=(0, 100), # 적절히 조절\n",
        "    ylim=(0, 20)   # 적절히 조절\n",
        ")\n",
        "plt.suptitle(\"Sentence Length vs. Token Edit Distance (Sampled)\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7L88l3q4I9Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aFJ3R0wJJ93"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPUzeoWMf9pE0wEpO5syjA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}