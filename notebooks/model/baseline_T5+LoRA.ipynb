{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOUbdnRNNV6FWFMhG5C6WL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dldmstj0531/GEC/blob/main/notebooks/model/baseline_T5%2BLoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 환경 설정 및 라이브러리 설치"
      ],
      "metadata": {
        "id": "lq1rswusKZdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1: 라이브러리 설치\n",
        "!pip install -q datasets transformers[torch] peft evaluate sacrebleu"
      ],
      "metadata": {
        "id": "VsaFxxqmelFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2: 라이브러리 임포트\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import evaluate # 평가 지표 로드\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "LXjlS4LiEabD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3: 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "cfvfs8DBmdS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 모델 및 LoRA 설정"
      ],
      "metadata": {
        "id": "rbGT2axJexSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m11Y3dOkENko"
      },
      "outputs": [],
      "source": [
        "# 2.1: T5 모델 및 토크나이저 로드\n",
        "MODEL_NAME = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2: LoRA 설정 (PEFT)\n",
        "# T5는 Seq2Seq 모델이므로 task_type을 명시.\n",
        "config = LoraConfig(\n",
        "    r=16,       # 8 or 16\n",
        "    lora_alpha=32,      # r * 2\n",
        "    target_modules=[\"q\", \"v\"],      # T5 경우 보통 `q`, `v` 레이어에 적용\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM  # T5 = SEQ_2_SEQ_LM\n",
        ")"
      ],
      "metadata": {
        "id": "nU_G-FkLEaMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3: 모델에 LoRA 적용\n",
        "peft_model = get_peft_model(model, config)\n",
        "# peft_model\n",
        "\n",
        "# 2.4: 학습 가능한 파라미터 확인\n",
        "print(\"--- LoRA 적용 후 학습 파라미터 ---\")\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "R-5UjT5TEaJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터 로드 및 전처리"
      ],
      "metadata": {
        "id": "7IXqpcybfWT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1: CSV 파일에서 데이터셋 로드\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/c4_200m.csv\"\n",
        "\n",
        "raw_train_dataset = load_dataset(\"csv\", data_files={\"train\": TRAIN_PATH}, split=\"train\")"
      ],
      "metadata": {
        "id": "6CtJuL3-EaF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2: 1만 개 랜덤 샘플링\n",
        "# (seed=42는 재현성을 위함. 변경 가능)\n",
        "if len(raw_train_dataset) > 10000:\n",
        "    sampled_train_dataset = raw_train_dataset.shuffle(seed=42).select(range(10000))\n",
        "else:\n",
        "    sampled_train_dataset = raw_train_dataset.shuffle(seed=42) # 1만개 이하면 그냥 섞기만 함\n",
        "\n",
        "print(f\"--- 원본 데이터 {len(raw_train_dataset)}개에서 {len(sampled_train_dataset)}개 샘플링 ---\")"
      ],
      "metadata": {
        "id": "rtuyUnHJEaC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.3: 샘플링된 5만 개를 훈련(train)과 검증(validation) 세트로 분할\n",
        "#       : 90% 훈련(45k), 10% 검증(5k)\n",
        "train_val_split = sampled_train_dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# 최종 데이터셋 구성 (이제 \"test\" 세트는 여기에 포함되지 않음)\n",
        "datasets = DatasetDict({\n",
        "    \"train\": train_val_split[\"train\"],\n",
        "    \"validation\": train_val_split[\"test\"],\n",
        "})\n",
        "\n",
        "print(\"--- 훈련/검증 데이터셋 구성 ---\")\n",
        "print(datasets)"
      ],
      "metadata": {
        "id": "KRVYrNdzEZ_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.4: T5 접두사(Prefix) 및 전처리 함수 정의\n",
        "PREFIX = \"grammar correction: \"\n",
        "MAX_INPUT_LENGTH = 128\n",
        "MAX_TARGET_LENGTH = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # 입력 (Noise): \"grammar correction: [오류 문장]\"\n",
        "    inputs = [PREFIX + doc for doc in examples[\"noise\"]]\n",
        "\n",
        "    # 타겟 (Clean): \"[수정된 문장]\"\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=MAX_INPUT_LENGTH,\n",
        "        truncation=True,\n",
        "        # padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # 타겟(레이블) 토크나이징\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            examples[\"clean\"],\n",
        "            max_length=MAX_TARGET_LENGTH,\n",
        "            truncation=True,\n",
        "            # padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "    # T5는 패딩된 레이블을 -100으로 설정하여 손실 계산에서 제외\n",
        "    # labels[\"input_ids\"] = [\n",
        "    #     [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
        "    # ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "h6mA0-P9EZ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.5: 전처리 함수 적용 (데이터셋 전체에 매핑)\n",
        "tokenized_datasets = datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=datasets[\"train\"].column_names\n",
        ")\n",
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "id": "evTIs9twEZ6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.6: 데이터 콜레이터 정의\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=peft_model\n",
        ")"
      ],
      "metadata": {
        "id": "oTdaD8XqEZ34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 평가 지표 (Metrics) 정의\n",
        "\n",
        "- \"validation\" 세트를 평가할 때 사용"
      ],
      "metadata": {
        "id": "9SurHCXpnkjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1: 평가 지표 로드 (sacreBLEU)\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    # 예측 결과(preds) 디코딩\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # 레이블(labels) 디코딩. (-100은 패딩이므로 무시)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # sacreBLEU 계산을 위해 후처리 (공백 제거)\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    # sacreBLEU는 [참조] 형식이 아닌 [[참조]] 형식을 요구\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "44fv561vEZ0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. TrainingArguments 및 Trainer 정의"
      ],
      "metadata": {
        "id": "uZ2_z0bJnrWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1: TrainingArguments 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "\n",
        "    # 배치 사이즈를 8 -> 4 -> 2로 줄여서 메모리 사용량 감소\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,  # eval 배치도 함께 줄이기.\n",
        "\n",
        "    # 줄어든 배치 사이즈를 보완 (4 * 2 = 8, 기존 배치와 동일한 효과)\n",
        "    gradient_accumulation_steps=4,\n",
        "\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "\n",
        "    eval_strategy=\"epoch\",            # 매 에포크마다 검증\n",
        "    save_strategy=\"epoch\",            # 매 에포크마다 모델 저장\n",
        "    load_best_model_at_end=True,      # 학습 종료 시 최고 성능 모델 로드\n",
        "\n",
        "    # metric_for_best_model=\"bleu\",     # \"bleu\"를 기준으로 최고 모델 저장\n",
        "    # greater_is_better=False,          # bleu 점수는 높을수록 좋음\n",
        "\n",
        "    metric_for_best_model=\"loss\",     # \"loss\"를 기준으로 최고 모델 저장\n",
        "    greater_is_better=False,          # Loss는 낮을수록 좋음\n",
        "\n",
        "    fp16=True,                        # (GPU 사용 시) 혼합 정밀도 학습\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "mjcR6OiYEZyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2: Trainer 정의\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "\n",
        "    # [수정] 이 라인을 주석 처리/삭제하여 평가 시 .generate()를 막음\n",
        "    # compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "cuklyhpBEZvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 모델 학습 시작"
      ],
      "metadata": {
        "id": "vRPCkaXypotN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch CUDA 메모리 할당 정책 변경 (단편화 방지)\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# 학습 시작 전, GPU 캐시를 한 번 비워줍니다.\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"--- LoRA 파인튜닝 시작 ---\")\n",
        "trainer.train()\n",
        "print(\"--- 학습 완료 ---\")\n",
        "\n",
        "# 학습 완료 후 최고 성능 모델 저장\n",
        "trainer.save_model(\"./results/best_t5_lora_model\")"
      ],
      "metadata": {
        "id": "UW1c6QZ9pYF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 공식 테스트셋 예측 (BEA-2019 제출용)"
      ],
      "metadata": {
        "id": "wZDPG_e3p9yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.1: 공식 테스트 파일(텍스트) 로드\n",
        "OFFICIAL_TEST_PATH = \"/content/drive/MyDrive/Projects/LikeLion/실전프로젝트02/wi+locness/test/ABCN.test.bea19.orig\"\n",
        "\n",
        "if not os.path.exists(OFFICIAL_TEST_PATH):\n",
        "    print(f\"경고: {OFFICIAL_TEST_PATH} 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
        "else:\n",
        "    print(f\"--- 공식 테스트 파일 로드: {OFFICIAL_TEST_PATH} ---\")\n",
        "    official_test_dataset = load_dataset(\"text\", data_files={\"test\": OFFICIAL_TEST_PATH})[\"test\"]\n",
        "\n",
        "    # 7.2: 테스트셋을 위한 전처리 함수 (정답[clean]이 없음)\n",
        "    def preprocess_test_function(examples):\n",
        "        # \"text\" 컬럼(원본 문장)에 접두사 추가\n",
        "        inputs = [PREFIX + doc for doc in examples[\"text\"]] # <--- PREFIX 변수가 이전에 정의되어 있어야 함\n",
        "\n",
        "        model_inputs = tokenizer(\n",
        "            inputs,\n",
        "            max_length=MAX_INPUT_LENGTH, # <--- MAX_INPUT_LENGTH 변수가 이전에 정의되어 있어야 함\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        return model_inputs\n",
        "\n",
        "    # 7.3: 테스트셋에 전처리 적용\n",
        "    print(\"--- 테스트셋 전처리 시작 ---\")\n",
        "    tokenized_test_set = official_test_dataset.map(\n",
        "        preprocess_test_function,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\"] # 원본 \"text\" 컬럼 제거\n",
        "    )\n",
        "    print(\"--- 테스트셋 전처리 완료 ---\")\n",
        "\n",
        "    # 7.4: .predict() 대신 .generate()를 사용한 직접 예측\n",
        "    print(\"--- 공식 테스트셋 예측 시작 (model.generate() 사용) ---\")\n",
        "\n",
        "    # ->> 모델과 디바이스 설정\n",
        "    # (trainer.model은 \"load_best_model_at_end=True\"에 의해 이미 최고 성능 모델임)\n",
        "    model = trainer.model\n",
        "    model.eval() # 평가 모드로 설정\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # ->> DataLoader 준비 (배치 처리를 위해)\n",
        "    tokenized_test_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "    # ->> GPU 메모리에 맞게 조절하세요 (16 or 32)\n",
        "    PREDICT_BATCH_SIZE = 16\n",
        "    test_dataloader = DataLoader(tokenized_test_set, batch_size=PREDICT_BATCH_SIZE)\n",
        "\n",
        "    decoded_preds = [] # 디코딩된 예측을 저장할 리스트\n",
        "\n",
        "    # ->> 배치 단위로 반복하며 .generate() 호출 (메모리 부족 방지)\n",
        "    with torch.no_grad(): # 그래디언트 계산 비활성화\n",
        "        for batch in tqdm(test_dataloader, desc=\"Generating predictions\"):\n",
        "            # 데이터를 GPU로 이동\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # model.generate() 호출\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=MAX_TARGET_LENGTH  # <--- 훈련 시 사용했던 'MAX_TARGET_LENGTH' 값\n",
        "                                              #      (혹은 128, 256 등 적절한 최대 길이)\n",
        "                # num_beams=5, # <--- 필요시 빔 서치 등 옵션 추가\n",
        "                # early_stopping=True\n",
        "            )\n",
        "\n",
        "            # 4. 결과 디코딩 및 저장\n",
        "            # 생성된 ID를 CPU로 다시 가져와서 디코딩\n",
        "            batch_preds = tokenizer.batch_decode(generated_ids.cpu(), skip_special_tokens=True)\n",
        "            decoded_preds.extend(batch_preds)\n",
        "\n",
        "    # --- 7.5: 예측 결과 디코딩 (위 루프에서 이미 완료됨) ---\n",
        "    print(\"--- 예측 완료 ---\")\n",
        "\n",
        "    # --- 7.6: 제출용 파일로 저장 (이 부분은 기존과 동일) ---\n",
        "    output_filename = \"submission.txt\"\n",
        "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for line in decoded_preds:\n",
        "            f.write(line.strip() + \"\\n\")\n",
        "\n",
        "    print(f\"--- 결과가 {output_filename} 에 저장되었습니다. ---\")\n",
        "    print(\"\\n--- 예측 샘플 5개 ---\")\n",
        "\n",
        "    # 5개 샘플 출력 (데이터셋 크기가 5보다 작은 경우 대비)\n",
        "    sample_count = min(5, len(official_test_dataset))\n",
        "    for i in range(sample_count):\n",
        "        print(f\"Original ({i+1}): {official_test_dataset[i]['text']}\") # official_test_dataset은 유지됨\n",
        "        print(f\"Corrected ({i+1}): {decoded_preds[i]}\\n\")"
      ],
      "metadata": {
        "id": "PpL7YoP6ps45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKX_ciPeqCj7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}